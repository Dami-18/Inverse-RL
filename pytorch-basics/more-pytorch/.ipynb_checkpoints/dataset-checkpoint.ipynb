{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebf90b7d-937a-4410-bcff-78ab7a297f53",
   "metadata": {},
   "source": [
    "### Custom Dataset for Grid world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "deddece7-52e6-4f91-bfc3-378025bb642f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "class GridWorldDataset(Dataset):\n",
    "    def __init__(self, num_grids, grid_size=(10,10)):\n",
    "        self.num_grids = num_grids # number of grids \n",
    "        self.grid_size = grid_size # by default size is set to 10x10\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_grids \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # 0 is empty space, 1 is obstacle\n",
    "        grid = np.random.choice([0, 1], size=self.grid_size, p=[0.8, 0.2])  # 80% empty, 20% obstacles\n",
    "        return torch.tensor(grid,dtype=torch.int) # return a tensor, so no transform needed, else add transform argument separately"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53abf923-f838-4617-b910-077ed9b51cf0",
   "metadata": {},
   "source": [
    "Adding complexity by including \"goal\" in each grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14fceb6f-eee3-4ff9-a9bd-8f0346e42620",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridWorldDataset(Dataset):\n",
    "    def __init__(self, num_grids, grid_size=(10,10)):\n",
    "        self.num_grids = num_grids # number of grids\n",
    "        self.grid_size = grid_size # by default size is set to 10x10\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_grids \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # 0 is empty space, 1 is obstacle\n",
    "        grid = np.random.choice([0, 1], size=self.grid_size, p=[0.8, 0.2])  # 80% empty, 20% obstacles\n",
    "        # select a goal randomly and set it to 2\n",
    "        index = np.random.choice(grid.shape[0],2) # returns index like [2,3]\n",
    "        grid[index] = 2 # set goal to \n",
    "        return {\n",
    "            'grid': torch.tensor(grid,dtype=int),\n",
    "            'goal': index\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d641f6a-dca0-4d11-8aaa-9fcf74794fb9",
   "metadata": {},
   "source": [
    "Creating dataloader for above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c269aa51-9e89-4780-bdc3-84bd6dd519de",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GridWorldDataset(1000,(10,10)) # let's say 1000 grid samples, this works for both the above cases\n",
    "dataloader = DataLoader(dataset, batch_size=100, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da6a1c1-7779-45b3-af7e-2c5dc0bef90e",
   "metadata": {},
   "source": [
    "`torch.utils.data.DataLoader` is an iterator which provides all these features. Parameters used should be clear. One parameter of interest is `collate_fn`. You can specify how exactly the samples need to be batched using `collate_fn`. However, default collate should work fine for most use cases.<br/>\n",
    "<br/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09801f49-8ef4-4fa6-b743-7946b47eeca3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
